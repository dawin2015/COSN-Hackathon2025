# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zzLEiLgxJxnjNZg7Sirr9k4dPqAu_3E1
"""

# -*- coding: utf-8 -*-
"""
EDA + 事件对齐（ChineseEEG-2） for:
sub-01_ses-littleprince_task-lis_run-110_ica_components.npy
并自动读取同路径的：
sub-01_ses-littleprince_task-lis_run-110_events.tsv

新增能力：
- 读取 *_events.tsv（BIDS: onset[sec], duration[sec], trial_type 等）
- 事件锁分段（支持基线校正），按 trial_type 分组求 ERP
- 组件级“诱发分数”与 SNR 指标，筛选 Top 组件
- 导出 erp_scores.csv；绘制平均 ERP、组件热图、Top K 组件曲线
"""

import os
import re
import json
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy import signal, stats

# =========（沿用：通用工具）=========
def parse_bids_from_filename(fname: str) -> dict:
    base = os.path.basename(fname)
    info = {}
    for key in ["sub", "ses", "task", "run"]:
        m = re.search(fr"{key}-([a-zA-Z0-9]+)", base)
        if m:
            info[key] = m.group(1)
    return info

def find_bids_json_for_sampling_rate(npy_path: str) -> float | None:
    d = os.path.dirname(os.path.abspath(npy_path))
    base = os.path.basename(npy_path)
    prefix = re.sub(r"_ica_components\.npy$", "", base)
    candidates = [os.path.join(d, f"{prefix}_eeg.json")]
    if not os.path.exists(candidates[0]):
        for f in os.listdir(d):
            if f.endswith("_eeg.json") and base.split("_")[0] in f:
                candidates.append(os.path.join(d, f))
    for path in candidates:
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as fp:
                    meta = json.load(fp)
                if "SamplingFrequency" in meta:
                    return float(meta["SamplingFrequency"])
            except Exception:
                pass
    return None

def load_npy_any(npy_path: str):
    return np.load(npy_path, allow_pickle=True)

def infer_time_component_axes(data: np.ndarray) -> tuple[int, int]:
    if data.ndim != 2:
        raise ValueError("期望二维数组")
    H, W = data.shape
    if max(H, W) >= 1000:
        time_axis = 0 if H > W else 1
        return (1 - time_axis), time_axis

    def mean_adj_corr(x, axis):
        if x.shape[axis] < 3:
            return 0.0
        if axis == 1:
            a = x[:, :-1]; b = x[:, 1:]
            num = np.sum((a - a.mean(axis=1, keepdims=True)) * (b - b.mean(axis=1, keepdims=True)), axis=1)
            den = np.sqrt(np.sum((a - a.mean(axis=1, keepdims=True))**2, axis=1) *
                          np.sum((b - b.mean(axis=1, keepdims=True))**2, axis=1))
            corr = np.where(den > 0, num / den, 0.0)
            return float(np.nanmean(corr))
        else:
            return mean_adj_corr(x.T, 1)
    c0 = mean_adj_corr(data, axis=0)
    c1 = mean_adj_corr(data, axis=1)
    time_axis = 0 if c0 > c1 else 1
    return (1 - time_axis), time_axis

def to_comp_time(data: np.ndarray, comp_axis: int, time_axis: int) -> np.ndarray:
    if comp_axis == 0 and time_axis == 1:
        return data
    elif comp_axis == 1 and time_axis == 0:
        return data.T
    return data

def memory_in_mb(arr: np.ndarray) -> float:
    return arr.nbytes / (1024**2)

# =========（沿用：频域）=========
def welch_psd(x: np.ndarray, sfreq: float, nperseg: int | None = None):
    if nperseg is None:
        nperseg = int(min(len(x), max(256, sfreq * 2)))
    f, pxx = signal.welch(x, fs=sfreq, nperseg=nperseg, detrend='constant')
    return f, pxx

def band_power_ratio(freqs, pxx, band_lo, band_hi, ref_lo=1.0, ref_hi=45.0):
    sel = (freqs >= band_lo) & (freqs < band_hi)
    ref = (freqs >= ref_lo) & (freqs < ref_hi)
    num = pxx[sel].sum()
    den = pxx[ref].sum() + 1e-12
    return float(num / den)

def detect_line_noise(freqs, pxx, possible=[50.0, 60.0], tol=0.8):
    ref = (freqs >= 45.0) & (freqs <= 65.0)
    ref_pow = pxx[ref].mean() + 1e-12
    score = 0.0
    for lf in possible:
        sel = (freqs >= (lf - tol)) & (freqs <= (lf + tol))
        peak = pxx[sel].max() if sel.any() else 0.0
        score = max(score, float(peak / ref_pow))
    return score

def autocorr_score(x: np.ndarray, max_lag: int = 50):
    x = x - np.mean(x)
    if np.allclose(x.std(), 0):
        return 0.0
    ac = signal.correlate(x, x, mode="full")
    mid = len(ac) // 2
    ac = ac[mid: mid + max_lag + 1]
    ac = ac / (ac[0] + 1e-12)
    return float(np.mean(np.abs(ac[1:])))

# =========（新增：事件读取与对齐）=========
def find_events_tsv_for_npy(npy_path: str) -> str | None:
    d = os.path.dirname(os.path.abspath(npy_path))
    base = os.path.basename(npy_path)
    prefix = re.sub(r"_ica_components\.npy$", "", base)
    candidate = os.path.join(d, f"{prefix}_events.tsv")
    if os.path.exists(candidate):
        return candidate
    # 兜底：同目录搜匹配 *_events.tsv
    for f in os.listdir(d):
        if f.endswith("_events.tsv") and base.split("_")[0] in f:
            return os.path.join(d, f)
    return None

def load_events(events_tsv: str) -> pd.DataFrame:
    df = pd.read_csv(events_tsv, sep="\t", dtype=str)  # 先以 str 读，防止混合类型报错
    # 标准列：onset, duration, trial_type（可能不全）
    # 转为数值
    for col in ["onset", "duration"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")
    # 填补 trial_type
    if "trial_type" not in df.columns:
        df["trial_type"] = "NA"
    # 清理无效 onset
    df = df[np.isfinite(df["onset"])].copy()
    df.sort_values("onset", inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df

def make_epochs(X: np.ndarray, sf: float, onsets_sec: np.ndarray,
                tmin: float=-0.2, tmax: float=0.8) -> tuple[np.ndarray, np.ndarray, np.ndarray]:
    """
    X: (n_comp, n_times)
    返回：
    - epochs: (n_events_kept, n_comp, n_times_epoch)  已做边界检查
    - kept_onsets_sec: 对应保留事件的 onset（秒）
    - times: 相对时间轴（秒），长度 n_times_epoch
    """
    n_comp, n_times = X.shape
    smin = int(round(tmin * sf))
    smax = int(round(tmax * sf))
    win = smax - smin + 1
    times = np.arange(smin, smax + 1) / sf

    kept = []
    kept_onsets = []
    for onset in onsets_sec:
        center = int(round(onset * sf))
        beg = center + smin
        end = center + smax
        if beg < 0 or end >= n_times:
            continue
        kept.append(X[:, beg:end+1])
        kept_onsets.append(onset)
    if not kept:
        return np.zeros((0, n_comp, win), dtype=float), np.array([], dtype=float), times
    epochs = np.stack(kept, axis=0)  # (E, C, T)
    return epochs, np.array(kept_onsets, dtype=float), times

def baseline_correction(epochs: np.ndarray, sf: float, times: np.ndarray,
                        bmin: float=-0.2, bmax: float=0.0) -> np.ndarray:
    """
    每个 trial、每个组件减去基线均值
    epochs: (E, C, T)
    """
    bsel = (times >= bmin) & (times <= bmax)
    if not np.any(bsel):
        return epochs
    base = epochs[:, :, bsel].mean(axis=2, keepdims=True)
    return epochs - base

def erp_and_scores(epochs: np.ndarray, times: np.ndarray,
                   post_win: tuple[float, float]=(0.05, 0.5)) -> tuple[np.ndarray, pd.DataFrame]:
    """
    计算 ERP（trial 平均）和组件级评分：
    - erp: (C, T)
    - scores: 每个组件的诱发指标（post 窗与 baseline 的幅度/能量差异）、SNR
    """
    if epochs.size == 0:
        return np.zeros((0, len(times))), pd.DataFrame(columns=[
            "component","n_trials","evoked_abs_mean","evoked_rms","snr","post_mean_abs","base_mean_abs"
        ])

    E, C, T = epochs.shape
    erp = epochs.mean(axis=0)  # (C, T)

    # 基线与事后窗口
    bsel = (times >= -0.2) & (times <= 0.0)
    psel = (times >= post_win[0]) & (times <= post_win[1])

    rows = []
    for c in range(C):
        x = erp[c]
        # 绝对幅度均值（post vs base）
        base_mean_abs = float(np.mean(np.abs(x[bsel]))) if np.any(bsel) else np.nan
        post_mean_abs = float(np.mean(np.abs(x[psel]))) if np.any(psel) else np.nan
        evoked_abs_mean = float(post_mean_abs - base_mean_abs)

        # RMS（post）
        evoked_rms = float(np.sqrt(np.mean(x[psel]**2))) if np.any(psel) else np.nan

        # SNR：以单 trail RMS 估计（post/base）
        # 若需要更稳健，可用 trial 级别 RMS 的均值比
        if E > 0 and np.any(psel) and np.any(bsel):
            rms_post_trials = np.sqrt(np.mean(epochs[:, c, :][:, psel]**2, axis=1))
            rms_base_trials = np.sqrt(np.mean(epochs[:, c, :][:, bsel]**2, axis=1)) + 1e-12
            snr = float(np.mean(rms_post_trials / rms_base_trials))
        else:
            snr = np.nan

        rows.append([c, E, evoked_abs_mean, evoked_rms, snr, post_mean_abs, base_mean_abs])

    score_df = pd.DataFrame(rows, columns=[
        "component","n_trials","evoked_abs_mean","evoked_rms","snr","post_mean_abs","base_mean_abs"
    ])
    return erp, score_df

# =========（沿用：作图，单图单用途，不指定颜色）=========
def plot_sample_components(X, sfreq, comps=(0,1,2), seconds=10, outdir="figs", prefix="sample"):
    os.makedirs(outdir, exist_ok=True)
    n_times = X.shape[1]
    N = int(min(n_times, seconds * sfreq))
    t = np.arange(N) / sfreq
    for c in comps:
        if c >= X.shape[0]: continue
        plt.figure(figsize=(9,3))
        plt.plot(t, X[c, :N])
        plt.xlabel("Time (s)"); plt.ylabel(f"ICA Comp {c} (a.u.)")
        plt.title(f"Component {c} - first {seconds}s")
        plt.tight_layout(); plt.savefig(os.path.join(outdir, f"{prefix}_comp{c}.png"), dpi=150); plt.close()

def plot_median_psd(X, sfreq, outdir="figs", prefix="psd"):
    os.makedirs(outdir, exist_ok=True)
    psds = []
    for c in range(X.shape[0]):
        f, pxx = welch_psd(X[c], sfreq)
        psds.append(pxx)
    psds = np.vstack(psds)
    med = np.median(psds, axis=0)
    plt.figure(figsize=(7,4))
    plt.semilogy(f, med)
    plt.xlabel("Frequency (Hz)"); plt.ylabel("Median PSD")
    plt.title("Median PSD across ICA components")
    plt.tight_layout(); plt.savefig(os.path.join(outdir, f"{prefix}_median.png"), dpi=150); plt.close()

def plot_one_psd(X, sfreq, comp=0, outdir="figs", prefix="psd"):
    os.makedirs(outdir, exist_ok=True)
    if comp >= X.shape[0]: return
    f, pxx = welch_psd(X[comp], sfreq)
    plt.figure(figsize=(7,4))
    plt.semilogy(f, pxx)
    plt.xlabel("Frequency (Hz)"); plt.ylabel("PSD")
    plt.title(f"PSD - Component {comp}")
    plt.tight_layout(); plt.savefig(os.path.join(outdir, f"{prefix}_comp{comp}.png"), dpi=150); plt.close()

def plot_erp_avg(erp: np.ndarray, times: np.ndarray, title: str, outpath: str):
    """组件平均 ERP（对组件求均值）"""
    if erp.size == 0: return
    mean_erp = erp.mean(axis=0)
    plt.figure(figsize=(8,3.6))
    plt.plot(times, mean_erp)
    plt.axvline(0, linestyle="--")
    plt.xlabel("Time (s)"); plt.ylabel("Mean ERP (a.u.)")
    plt.title(title)
    plt.tight_layout(); plt.savefig(outpath, dpi=150); plt.close()

def plot_erp_heatmap(erp: np.ndarray, times: np.ndarray, title: str, outpath: str):
    """组件×时间 热图（绝对值便于观察能量分布）"""
    if erp.size == 0: return
    plt.figure(figsize=(8, 5))
    plt.imshow(np.abs(erp), aspect='auto', origin='lower',
               extent=[times[0], times[-1], 0, erp.shape[0]])
    plt.axvline(0, linestyle="--")
    plt.xlabel("Time (s)"); plt.ylabel("Component")
    plt.title(title + " | abs(ERP)")
    plt.colorbar()
    plt.tight_layout(); plt.savefig(outpath, dpi=150); plt.close()

def plot_topk_components_with_trials(
    epochs: np.ndarray,           # (E, C, T) 事件锁分段（已基线校正）
    times: np.ndarray,            # (T,)
    score_df: pd.DataFrame,       # 含 component / 指标列
    k: int,
    metric: str,                  # "evoked_abs_mean" 或 "snr"
    title_prefix: str,            # 用于文件名与标题，如 "ERP_<trialtype>"
    outdir: str,
    max_trials_shown: int = 30    # 为避免过密，最多画这么多 trial 细线
):
    """
    每张图只画 Top-K 中的一个组件（单图单用途），包含：
    - trial 级细线（最多 max_trials_shown 条，均匀抽样）
    - ERP 均值粗线
    - 95% CI 阴影（mean ± 1.96 * std/sqrt(n)）
    """
    if epochs.size == 0 or score_df.empty:
        return
    os.makedirs(outdir, exist_ok=True)
    top = score_df.sort_values(by=metric, ascending=False).head(k)

    E, C, T = epochs.shape
    # 均匀抽样 trial 索引
    if E <= max_trials_shown:
        show_idx = np.arange(E)
    else:
        show_idx = np.unique(np.linspace(0, E - 1, max_trials_shown).astype(int))

    for _, row in top.iterrows():
        c = int(row["component"])
        # (E, T)
        comp_trials = epochs[:, c, :]
        trial_mean = comp_trials.mean(axis=0)
        trial_std  = comp_trials.std(axis=0, ddof=1) if E > 1 else np.zeros_like(trial_mean)
        ci95 = 1.96 * (trial_std / np.sqrt(max(E, 1)))

        # 绘图
        plt.figure(figsize=(8, 3.6))
        # trial 细线
        for idx in show_idx:
            plt.plot(times, comp_trials[idx, :], linewidth=0.5, alpha=0.6)
        # 95% CI 阴影
        plt.fill_between(times, trial_mean - ci95, trial_mean + ci95, alpha=0.25)
        # 均值粗线
        plt.plot(times, trial_mean, linewidth=2.0)
        plt.axvline(0, linestyle="--")
        plt.xlabel("Time (s)")
        plt.ylabel(f"Comp {c} (a.u.)")
        plt.title(f"{title_prefix} | Comp {c} | {metric}={row[metric]:.3f} | n={E}")
        plt.tight_layout()
        fn = f"{title_prefix}_top_{metric}_comp{c}_with_trials.png"
        plt.savefig(os.path.join(outdir, fn), dpi=150)
        plt.close()

def plot_top_components_bar(
    score_df: pd.DataFrame,
    metric: str,          # "evoked_abs_mean" 或 "snr"
    k: int,
    title: str,
    outpath: str
):
    """
    生成 Top-K 组件的条形图（单图单用途）。
    注意：不指定颜色，使用 matplotlib 默认样式。
    """
    if score_df.empty or metric not in score_df.columns:
        return
    top = score_df.sort_values(by=metric, ascending=False).head(k)
    comps = top["component"].astype(int).to_numpy()
    vals  = top[metric].to_numpy()

    plt.figure(figsize=(7.2, 4))
    plt.bar([str(c) for c in comps], vals)
    plt.xlabel("Component (Top-K)")
    plt.ylabel(metric)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(outpath, dpi=150)
    plt.close()


def plot_topk_components(erp: np.ndarray, times: np.ndarray, score_df: pd.DataFrame,
                         k: int, metric: str, title_prefix: str, outdir: str):
    """按 metric 选 Top-K 组件绘图"""
    if erp.size == 0 or score_df.empty: return
    os.makedirs(outdir, exist_ok=True)
    top = score_df.sort_values(by=metric, ascending=False).head(k)
    for _, row in top.iterrows():
        c = int(row["component"])
        plt.figure(figsize=(8,3))
        plt.plot(times, erp[c])
        plt.axvline(0, linestyle="--")
        plt.xlabel("Time (s)"); plt.ylabel(f"Comp {c} ERP")
        plt.title(f"{title_prefix} | Comp {c} | {metric}={row[metric]:.3f}")
        plt.tight_layout(); plt.savefig(os.path.join(outdir, f"{title_prefix}_top_{metric}_comp{c}.png"), dpi=150); plt.close()

# =========（主流程）=========
def run_eda_with_events(npy_path: str,
                        default_sfreq: float = 250.0,
                        preview_components=(0,1,2),
                        tmin: float=-0.2, tmax: float=0.8,
                        post_win=(0.05, 0.5),
                        topk: int=5):
    print(f"[INFO] Loading: {npy_path}")
    raw = load_npy_any(npy_path)

    if isinstance(raw, dict):
        for k in ["activations","activation","ica_components","sources","S","X"]:
            if k in raw and isinstance(raw[k], np.ndarray):
                data = raw[k]; break
        else:
            arrs = [v for v in raw.values() if isinstance(v, np.ndarray)]
            if not arrs: raise ValueError("dict 中未找到 ndarray")
            data = arrs[0]
    elif isinstance(raw, (list, tuple)):
        arrs = [x for x in raw if isinstance(x, np.ndarray)]
        if not arrs: raise ValueError("list/tuple 中未找到 ndarray")
        data = arrs[0]
    elif isinstance(raw, np.ndarray):
        data = raw
    else:
        raise ValueError(f"不支持的类型：{type(raw)}")

    if data.ndim != 2:
        raise ValueError(f"期望二维矩阵，得到 {data.shape}")

    print(f"[INFO] Raw shape: {data.shape}, dtype: {data.dtype}, mem: {memory_in_mb(data):.2f} MB")
    comp_axis, time_axis = infer_time_component_axes(data)
    X = to_comp_time(data, comp_axis, time_axis)  # (C, T)
    C, T = X.shape
    print(f"[INFO] Interpreted as (n_components={C}, n_times={T})")

    sf = find_bids_json_for_sampling_rate(npy_path) or float(default_sfreq)
    print(f"[INFO] SamplingFrequency: {sf} Hz")

    bids = parse_bids_from_filename(npy_path)
    duration_sec = T / sf

    # —— 基础统计（与原 EDA 一致）——
    nan_cnt = int(np.isnan(X).sum())
    inf_cnt = int(np.isinf(X).sum())

    comp_stats = []
    for c in range(C):
        x = X[c].astype(float)
        x = x[np.isfinite(x)]
        if x.size == 0:
            mu = sd = sk = ku = p2p = ac = 0.0
        else:
            mu = float(np.mean(x)); sd = float(np.std(x))
            sk = float(stats.skew(x)); ku = float(stats.kurtosis(x))
            p2p = float(np.ptp(x)); ac = autocorr_score(x, max_lag=min(200, int(sf)))
        comp_stats.append((c, mu, sd, sk, ku, p2p, ac))
    df = pd.DataFrame(comp_stats, columns=[
        "component","mean","std","skew","kurtosis","peak_to_peak","autocorr_avg"
    ])

    band_defs = {
        "delta_1_4": (1.,4.), "theta_4_8": (4.,8.), "alpha_8_13": (8.,13.),
        "beta_13_30": (13.,30.), "gamma_30_45": (30.,45.)
    }
    line_scores = []
    band_ratios = {k: [] for k in band_defs}
    for c in range(C):
        f, pxx = welch_psd(X[c], sf)
        for name, (lo, hi) in band_defs.items():
            band_ratios[name].append(band_power_ratio(f, pxx, lo, hi))
        line_scores.append(detect_line_noise(f, pxx))
    for name, vals in band_ratios.items():
        df[name] = vals
    df["line_noise_score"] = line_scores
    df["blink_like_score"]  = 0.6*df["delta_1_4"] + 0.2*np.maximum(0, df["kurtosis"]) + 0.2*df["autocorr_avg"]
    df["muscle_like_score"] = 0.8*df["gamma_30_45"] + 0.2*(1 - df["autocorr_avg"])
    df["line_like_score"]   = df["line_noise_score"]

    # —— 事件读取与对齐 ——
    events_path = find_events_tsv_for_npy(npy_path)
    if events_path is None:
        print("[WARN] 未找到 *_events.tsv，跳过事件对齐分析。")
        # 仍导出基础 EDA
        pd.DataFrame([{
            "file": os.path.basename(npy_path),
            "n_components": C, "n_times": T, "sampling_hz": sf, "duration_sec": duration_sec,
            "nan_total": nan_cnt, "inf_total": inf_cnt,
            "comp_axis_in_raw": comp_axis, "time_axis_in_raw": time_axis, **bids
        }]).to_csv("eda_meta.csv", index=False)
        df.to_csv("eda_report.csv", index=False)
        os.makedirs("figs", exist_ok=True)
        plot_sample_components(X, sf, preview_components, 10, "figs", "sample")
        plot_median_psd(X, sf, "figs", "psd")
        for c in preview_components:
            plot_one_psd(X, sf, c, "figs", "psd")
        print("[DONE] 基础 EDA 完成。")
        return

    print(f"[INFO] Loading events: {events_path}")
    ev = load_events(events_path)
    print(f"[INFO] Events rows: {len(ev)} | columns: {list(ev.columns)}")

    # 按 trial_type 分组（若缺失则全为 "NA"）
    groups = {}
    for trial_type, gdf in ev.groupby("trial_type"):
        onsets = gdf["onset"].to_numpy(dtype=float)
        groups[trial_type] = onsets

    # —— 构造与校正 epochs ——
    # 统一时间窗
    all_scores = []
    os.makedirs("figs", exist_ok=True)

    # 保存 meta
    pd.DataFrame([{
        "file": os.path.basename(npy_path),
        "events_file": os.path.basename(events_path),
        "n_components": C, "n_times": T, "sampling_hz": sf, "duration_sec": duration_sec,
        "nan_total": nan_cnt, "inf_total": inf_cnt,
        "comp_axis_in_raw": comp_axis, "time_axis_in_raw": time_axis, **bids
    }]).to_csv("eda_meta.csv", index=False)

    # 先输出基础 EDA 表
    df.to_csv("eda_report.csv", index=False)

    # 对每个 trial_type 做 ERP + 评分
    for tt, onsets in groups.items():
        epochs, kept_onsets, times = make_epochs(X, sf, onsets, tmin=tmin, tmax=tmax)
        if epochs.shape[0] == 0:
            print(f"[WARN] trial_type={tt} 无可用事件（窗口越界），跳过。")
            continue
        # 基线校正
        epochs = baseline_correction(epochs, sf, times, bmin=-0.2, bmax=0.0)
        erp, score_df = erp_and_scores(epochs, times, post_win=post_win)
        score_df["trial_type"] = tt
        all_scores.append(score_df)

        # 作图
        safe_tt = re.sub(r"[^a-zA-Z0-9_\-]", "_", str(tt))
        plot_erp_avg(erp, times, f"Mean ERP | {tt} | n={epochs.shape[0]}", f"figs/erp_mean_{safe_tt}.png")
        plot_erp_heatmap(erp, times, f"ERP Heatmap | {tt} | n={epochs.shape[0]}", f"figs/erp_heatmap_{safe_tt}.png")

        # === 新增：为热图配套的 Top 条形图（两个指标各一张） ===
        plot_top_components_bar(
            score_df, "evoked_abs_mean", topk,
            title=f"Top-{topk} Components by evoked_abs_mean | {tt}",
            outpath=f"figs/erp_heatmap_{safe_tt}_topbar_evoked_abs_mean.png"
        )
        plot_top_components_bar(
            score_df, "snr", topk,
            title=f"Top-{topk} Components by snr | {tt}",
            outpath=f"figs/erp_heatmap_{safe_tt}_topbar_snr.png"
        )

        plot_topk_components(erp, times, score_df, topk, "evoked_abs_mean",
                             f"ERP_{safe_tt}", outdir="figs")
        plot_topk_components(erp, times, score_df, topk, "snr",
                             f"ERP_{safe_tt}", outdir="figs")

        # === 新增：Top 组件 ERP（trial 细线 + 95%CI 阴影） ===
        plot_topk_components_with_trials(
            epochs, times, score_df, topk, "evoked_abs_mean", f"ERP_{safe_tt}", outdir="figs", max_trials_shown=30
        )
        plot_topk_components_with_trials(
            epochs, times, score_df, topk, "snr", f"ERP_{safe_tt}", outdir="figs", max_trials_shown=30
        )


    if all_scores:
        erp_scores = pd.concat(all_scores, ignore_index=True)
        erp_scores.to_csv("erp_scores.csv", index=False)
        print(f"[INFO] Saved: erp_scores.csv, eda_report.csv, eda_meta.csv and figs/*.png")
    else:
        print("[WARN] 未得到可用的 ERP 评分（可能所有事件均越界）。")

    # 仍输出基础的 PSD/时域预览
    plot_sample_components(X, sf, preview_components, 10, "figs", "sample")
    plot_median_psd(X, sf, "figs", "psd")
    for c in preview_components:
        plot_one_psd(X, sf, c, "figs", "psd")

    print("[DONE] EDA + 事件对齐完成。")

if __name__ == "__main__":
    # ======= 修改为你的实际路径 =======
    npy_path = "/content/ChineseEEG2/sub-01/sub-01/ses-littleprince/eeg/sub-01_ses-littleprince_task-lis_run-110_ica_components.npy"
    default_sfreq = 1000.0               # 若无 *_eeg.json 时兜底采样率
    preview_components = (0, 1, 2)      # 时域/PSD 预览
    # 事件锁参数（相对 onset 的时间窗与 post 统计窗）
    tmin, tmax = -0.2, 0.8              # 事件窗 [-200ms, +800ms]
    post_win = (0.05, 0.5)              # 用于评分的事后窗
    topk = 5                            # 绘图时每类挑选的 Top 组件数

    run_eda_with_events(npy_path, default_sfreq, preview_components, tmin, tmax, post_win, topk)